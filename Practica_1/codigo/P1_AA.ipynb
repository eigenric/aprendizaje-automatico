{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P1-AA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Práctica 1 - Aprendizaje Automático Búsqueda Iterativa de Óptimos y Regresión Lineal\n",
        "\n",
        "Límite de entrega: 3 de Abril de 2022 a las 23:59 (PRADO)\\\n",
        "Valoración máxima: 12 puntos (+2 puntos de Bonus)\n",
        "\n",
        "Es obligatorio presentar un informe con las valoraciones y decisiones adoptadas en el desarrollo de cada uno de\n",
        "los apartados. En dicho informe se incluirán los gráficos generados. También deberá incluirse una valoración sobre la\n",
        "calidad de los resultados encontrados. Sin este informe se considera que el trabajo NO ha sido presentado. El informe debe estar integrado en este mismo cuaderno\n",
        "(intercalando texto, código y resultados)."
      ],
      "metadata": {
        "id": "YmqxgSQBgcaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. EJERCICIO SOBRE LA BÚSQUEDA ITERATIVA DE  ÓPTIMOS (6.5 puntos)"
      ],
      "metadata": {
        "id": "CIXhq6P-1T9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EJERCICIO.1.1:  1 punto.\\\n",
        " Implementar el algoritmo de gradiente descendente."
      ],
      "metadata": {
        "id": "Kfhz4ZO0h544"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7Xstd_gf1gyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EJERCICIO.1.2: 2 puntos\\\n",
        " Considerar la función $E(u, v) = (uve^{(−u^2−v^2)})^2$. Usar gradiente descendente para\n",
        "encontrar un mınimo de esta función, comenzando desde el punto $(u, v) = (0.5, -0.5)$ y usando\n",
        "una tasa de aprendizaje $\\lambda = 0.1$.\\\n",
        "**a**) Calcular analíticamente y mostrar la expresión del gradiente de la función $E(u, v)$.\\\n",
        "**b**) ¿Cuántas iteraciones tarda el algoritmo en obtener por primera vez un valor de $E(u, v)$ inferior a $10^{−8}$.\\\n",
        "**c**) ¿En qué coordenadas $(u, v)$ se alcanzó por primera vez un valor igual o menor que $10^{-8}$ en el apartado anterior\n"
      ],
      "metadata": {
        "id": "NECDhrUfiFnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5JHoi8dxq1QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EJERCICIO.1.3: 2 puntos\\\n",
        "Considerar ahora la función $f(x, y) = x^2 + 2y^2 + 2sin(2\\pi x)sin(\\pi y)$ \\\n",
        "\n",
        "**a**) Usar gradiente descendente para minimizar esta funcin. Usar como punto inicial $(x_0 =\n",
        "-1, y_0 = 1)$, (tasa de aprendizaje $\\eta$ = 0,01 y un máximo de 50 iteraciones. Generar un\n",
        "gráfico de cómo desciende el valor de la función con las iteraciones. Repetir el experimento pero usando $\\eta$ = 0,1, comentar las diferencias y su dependencia de $\\eta$. \\\n",
        "**b**) Obtener el valor mínimo y los valores de las variables $(x, y)$ en donde se alcanzan cuando\n",
        "el punto de inicio se fija en: (-0.5, -0.5), (1, 1), (2.1,-2.1), (-3, 3), (-2, 2). Generar una\n",
        "tabla con los valores obtenidos. Comentar la dependencia del punto inicial."
      ],
      "metadata": {
        "id": "HGC7k6u2q14Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "i7u_2Ni0sbFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EJERCICIO.1.4: (1.5 punto)\\\n",
        " ¿Cuál sería su conclusión sobre la verdadera dificultad de encontrar el mínimo\n",
        "global de una función arbitraria?"
      ],
      "metadata": {
        "id": "wkDa54xMscsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3qCUZ877zE6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 EJERCICIO SOBRE REGRESIÓN LINEAL (5.5 puntos)\n",
        "Este ejercicio ajusta modelos de regresión a vectores de características extraídos a partir de\n",
        "imágenes de dígitos manuscritos. En particular, se extraen dos características concretas que miden el valor medio del nivel de gris y la simetría del dígito respecto de su eje vertical. Solo se seleccionarán\n",
        "para este ejercicio las imágenes de los números 1 y 5."
      ],
      "metadata": {
        "id": "jmWMpfUDs3ju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EJERCICIO.2.1:  2.5 puntos\\\n",
        " Estimar un modelo de regresión lineal, a partir de los datos proporcionados por\n",
        "los vectores de características dados, usando tanto el algoritmo de la pseudo-inversa como el\n",
        "gradiente descendente estocástico (SGD). Las etiquetas serán $\\{-1,1\\}$, una por cada vector de\n",
        "cada uno de los números. Pintar las soluciones obtenidas junto con los datos usados en el\n",
        "ajuste. Valorar la bondad del resultado usando $E_{in}$ y $E_{out}$ (para $E_{out}$ calcular las predicciones\n",
        "usando los datos del fichero de test)."
      ],
      "metadata": {
        "id": "l-sAV0qNtcBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9WFcsJn5tbA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EJERCICIO.2.2:  3 puntos\\\n",
        " En este apartado exploramos cónmo se transforman los errores Ein y Eout cuan-\n",
        "do aumentamos la complejidad del modelo lineal usado. Ahora hacemos uso de la función\n",
        "$simula\\_unif (N, 2, size)$ que nos devuelve N coordenadas 2D de puntos uniformemente mues-\n",
        "treados dentro del cuadrado definido por $[−size, size]\\times[−size, size]$. Se debe realizar el siguiente experimento: \\\n",
        "**a**) Generar una muestra de entrenamiento de $N = 1000$ puntos en el cuadrado $X = [−1, 1]\\times\n",
        "[−1, 1]$. Pintar el mapa de puntos 2D.\\\n",
        "**b**) Consideremos la función $f(x_1, x_2) = sign((x_1 − 0,2)^2 + x_2^2 − 0,6)$ que usaremos para\n",
        "asignar una etiqueta a cada punto de la muestra anterior. Introducimos ruido sobre las\n",
        "etiquetas cambiando aleatoriamente el signo de un $10\\%$ de las mismas. Pintar el mapa\n",
        "de etiquetas obtenido.\\\n",
        "**c**) Usando como vector de características (1, x1, x2), ajustar un modelo de regresión lineal al conjunto de datos generado y estimar los pesos ${\\bf w}$. Estimar el error de ajuste $E_{in}$ usando SGD. \\\n",
        "**d**) Ejecutar todo el experimento definido por (a)-(c) 1000 veces (generamos 1000 muestras\n",
        "diferentes) y calcular el valor medio de los errores $E_{in}$ de las 1000 muestras.\n",
        "Generar 1000 puntos nuevos por cada iteración y calcular con ellos el valor de $E_{out}$\n",
        "en dicha iteración. Calcular el valor medio de $E_{out}$ en todas las iteraciones. \\\n",
        "**e**) Valore qué tan bueno considera que es el ajuste con este modelo lineal a la vista de los\n",
        "valores medios obtenidos de $E_{in}$ y $E_{out}$.\n",
        "\n",
        "*   Repetir el mismo experimento anterior pero usando características no lineales. Ahora\n",
        "usaremos el siguiente vector de características: $\\Phi(x) = (1, x_1, x_1^2,x_1x_2, x_2, x_2^2)$. Ajustar el nuevo modelo de regresión lineal y calcular el nuevo vector de pesos $\\bf\\hat w$. Calcular los errores promedio de $E_{in}$ y $E_{out}$.\n",
        "*   A la vista de los resultados de los errores promedios $E_{in}$ y $E_{out}$ obtenidos en los dos experimentos, ¿qué modelo considera que es el más adecuado? Justifique la respuesta. \n",
        " "
      ],
      "metadata": {
        "id": "zecTssa_uWed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C82sezDNuU2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BONUS** (2 puntos) \n",
        "**El BONUS solo se tendrá en cuenta si se ha obtenido al menos el 75 % de los puntos de la parte obligatoria**\n",
        "\n",
        "Implementar el algoritmo de minimizaciónn de Newton y aplicarlo a la función $f(x, y)$ dada en el Ejercicio 1.3. Desarrolle los mismos experimentos usando los mismos puntos de inicio.\n",
        "Generar un gráfico de cómo desciende el valor de la función con las iteraciones. Extraer conclusiones sobre las conductas de los algoritmos comparando la curva de decrecimiento de la función calculada en el apartado anterior y la correspondiente obtenida con gradiente descendente"
      ],
      "metadata": {
        "id": "cR052dGHzRkW"
      }
    }
  ]
}